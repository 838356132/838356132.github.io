#!title:    新词发现
#!date:     2017-10-16
#!authors:  
#!cover:    
#!type:     C
#!tags:     

#!content

# 基于大规模语料统计的新词发现

> 本文是对顾森（Matrix67）文章 [http://www.csdn.net/article/2013-05-08/2815186]() 和 [http://www.matrix67.com/blog/archives/5044]() 的学习笔记

传统的新词发现方法有一个逻辑上的怪圈：新词发现依赖于分词结果，分词结果依赖于词库，然而新词并不存在于词库中，这样得到的“新词”结果就无法令人信任。为了跳出这个逻辑怪圈，基于大规模语料的新词发现方法抛弃了词库，对大规模语料中可能成词的片段进行分析，得到所有可能的分词结果，再与已有词库进行比对，得到新词。

## 新词特征指标

词是参与成句的最小完整单位。因此，判断一个短片段是否成词，需要从“最小”和“完整”两个方面入手。完整性显得更重要，因此首先考虑短片段组合的稳固程度。

## 内部凝固度

词是更细粒度的词稳定组合在一起形成的，因此使用**凝固度**这一指标衡量若干片段的组合出现的概率大小。

- 对于可能成词AB的片段A和B，两者的出现频率$P(A)$和$P(B)$。
- 若二者并不成词，也即在文本中完全随机出现，则词AB在文本中出现的概率应为$P(A)\cdot P(B)$。
- 而文本中AB的实际出现频率为$P(AB)$：若$P(AB)$远高于$P(A)\cdot P(B)$，那么可初步认为AB是一个成词组合。

按照这个标准，很容易找到诸如“忐忑”、“蜘蛛”、“蟑螂”、“彷徨”这样的双字**联绵词**，因为联绵词中单字单独出现的概率极低。

对于多字词而言，有多种划分片段的方式。划分方式不同，按照上述方法计算得到的$P(A)\cdot P(B)$就截然不同。

> 作为一个无知识库的抽词程序，我们并不知道“电影院”是“电影”加“院”得来的……如果我们把“电影院”看作是“电”加“影院”所得，由此得到的凝合程度会更高一些。

因此，并不能简单地用某一种划分计算得到的$P(A)\cdot P(B)$作为新词内部凝固度指标，而应枚举各种划分方式，选出**最小**的$P(A)\cdot P(B)$，计算$P(AB)$与$P(A)\cdot P(B)$的比值，作为可用的凝固度指标。凝固度指标实际上就是互信息。

> 在整个2400万字的数据中，“电影”一共出现了2774次，出现的概率约为0.000113。“院”字则出现了4797次，出现的概率约为0.0001969。如果两者之间真的毫无关系，它们恰好拼在了一起的概率就应该是0.000113×0.0001969=2.223E–8。但事实上，“电影院”在语料中一共出现了175次，出现概率约为7.183E–6，是预测值的300多倍。

> 类似地，统计可得“的”字的出现概率约为0.0166，因而“的”和“电影”随机组合到了一起的理论概率值为0.0166×0.000113=1.875E–6，这与“的电影”出现的真实概率很接近——真实概率约为1.6E–5，是预测值的8.5倍。

## 运用自由度

内部凝合并不是判断文本片段是否成词的充分条件。如果只考虑内部凝合度的话，并不能确定新词的外部边界，得到的新词很可能会“偏短”。例如：

> 考虑“被子”和“辈子”这两个片段。我们可以说“买被子”、“盖被子”、 “进被子”、“好被子”、“这被子”等，在“被子”前面加各种字；但“辈子”的用法却非常固定，除了“一辈子”、“这辈子”、“上辈子”、“下辈子”，基 本上“辈子”前面不能加别的字了。“辈子”这个文本片段左边可以出现的字太有限，以至于直觉上我们可能会认为，“辈子”并不单独成词，真正成词的其实是 “一辈子”、“这辈子”之类的整体。

因此，判断一个片段是否为新词，除了其内部的具有稳定的结构之外，它本身要足够“自由”去参与成句。换句话说就是，片段的左侧和右侧出现的词汇要有足够大的多样性。

描述“多样性”的指标就是**熵**。对于一个随机系统而言，它的每个状态都蕴含了一定的信息量，状态发生的概率越低，状态提供的信息量就越大。对系统中所有状态具备的信息量按发生概率进行加权平均，就得到了系统的信息熵。也就是说，信息熵是系统信息量的期望。信息熵越高，意味着系统内部的状态越丰富、系统越混乱；信息熵越低，意味着系统内部的状态越贫乏、系统越规律。

新词运用自由度的计算方法如下：

+ 提取左邻字和右邻字集合；
+ 计算每个左右邻字的出现频率并计算左右邻字信息熵；
+ 取二者较小者作为运用自由度指标。

之所以要取二者较小者作为自由度指标，是因为有些词具有固定前（后）缀的特性，例如“共产”（共产党、共产主义…）、“清华”（清华大学、清华学子…）、“夫斯基”这样的后缀词，而这样的词显然是不成词的。

> 在实际运用中你会发现，文本片段的凝固程度和自由程度，两种判断标准缺一不可。只看凝固程度的话，程序会找出“巧克”、“俄罗”、“颜六色”、“柴可夫”等实际上是“半个词”的片段；只看自由程度的话，程序则会把“吃了一顿”、“看了一遍”、 “睡了一晚”、“去了一趟”中的“了一”提取出来，因为它的左右邻字都太丰富了。

